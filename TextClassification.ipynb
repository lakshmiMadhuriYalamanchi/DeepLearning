{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TextClassification.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPtIRbhqR8CuBoy5MrljC7L",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lakshmiMadhuriYalamanchi/DeepLearning/blob/master/TextClassification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_WJZ_LQPswOR",
        "colab_type": "code",
        "outputId": "53dcdd95-8dd8-4b06-f1b0-203f4c5b7bff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        }
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Loading the spam data\n",
        "# ham is the label for non-spam messages\n",
        "spam = pd.read_csv('spam.csv')\n",
        "spam.head(10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ham</td>\n",
              "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ham</td>\n",
              "      <td>Ok lar... Joking wif u oni...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>spam</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ham</td>\n",
              "      <td>U dun say so early hor... U c already then say...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ham</td>\n",
              "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>spam</td>\n",
              "      <td>FreeMsg Hey there darling it's been 3 week's n...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>ham</td>\n",
              "      <td>Even my brother is not like to speak with me. ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>ham</td>\n",
              "      <td>As per your request 'Melle Melle (Oru Minnamin...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>spam</td>\n",
              "      <td>WINNER!! As a valued network customer you have...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>spam</td>\n",
              "      <td>Had your mobile 11 months or more? U R entitle...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  label                                               text\n",
              "0   ham  Go until jurong point, crazy.. Available only ...\n",
              "1   ham                      Ok lar... Joking wif u oni...\n",
              "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
              "3   ham  U dun say so early hor... U c already then say...\n",
              "4   ham  Nah I don't think he goes to usf, he lives aro...\n",
              "5  spam  FreeMsg Hey there darling it's been 3 week's n...\n",
              "6   ham  Even my brother is not like to speak with me. ...\n",
              "7   ham  As per your request 'Melle Melle (Oru Minnamin...\n",
              "8  spam  WINNER!! As a valued network customer you have...\n",
              "9  spam  Had your mobile 11 months or more? U R entitle..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jC4Ka2iRodxV",
        "colab_type": "text"
      },
      "source": [
        "**Bag of words**\n",
        "**TF-IDF**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M-f-P1W2ouRD",
        "colab_type": "text"
      },
      "source": [
        "**Build a bag of words**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BV-Rrn3Djymm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import spacy\n",
        "\n",
        "# Create an empty model\n",
        "nlp = spacy.blank(\"en\")\n",
        "\n",
        "# Create the TextCategorizer with exclusive classes and \"bow\" architecture\n",
        "textcat = nlp.create_pipe(\n",
        "              \"textcat\",\n",
        "              config={\n",
        "                \"exclusive_classes\": True,\n",
        "                \"architecture\": \"bow\"})\n",
        "\n",
        "# Add the TextCategorizer to the empty model\n",
        "nlp.add_pipe(textcat)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y25ExPUwpG2V",
        "colab_type": "code",
        "outputId": "f05995eb-8ded-4b95-b9df-4a4c434ee242",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "# Add labels to text classifier\n",
        "textcat.add_label(\"ham\")\n",
        "textcat.add_label(\"spam\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J4dLISq7pL7_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_texts = spam['text'].values\n",
        "train_labels = [{'cats': {'ham': label == 'ham',\n",
        "                          'spam': label == 'spam'}} \n",
        "                      for label in spam['label']]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RM_4JBmMqqto",
        "colab_type": "code",
        "outputId": "399b1fd1-0f66-4cb7-8145-84d18f04b3e6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 120
        }
      },
      "source": [
        "train_data = list(zip(train_texts, train_labels))\n",
        "train_data[:3]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...',\n",
              "  {'cats': {'ham': True, 'spam': False}}),\n",
              " ('Ok lar... Joking wif u oni...', {'cats': {'ham': True, 'spam': False}}),\n",
              " (\"Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's\",\n",
              "  {'cats': {'ham': False, 'spam': True}})]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X7RvvLqkqu67",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from spacy.util import minibatch\n",
        "\n",
        "spacy.util.fix_random_seed(1)\n",
        "optimizer = nlp.begin_training()\n",
        "\n",
        "# Create the batch generator with batch size = 8\n",
        "batches = minibatch(train_data, size=8)\n",
        "# Iterate through minibatches\n",
        "for batch in batches:\n",
        "    # Each batch is a list of (text, label) but we need to\n",
        "    # send separate lists for texts and labels to update().\n",
        "    # This is a quick way to split a list of tuples into lists\n",
        "    texts, labels = zip(*batch)\n",
        "    nlp.update(texts, labels, sgd=optimizer)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a6AoIv5_rR01",
        "colab_type": "code",
        "outputId": "c717defe-221b-421b-b8db-60ff8a1339c3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 183
        }
      },
      "source": [
        "import random\n",
        "\n",
        "random.seed(1)\n",
        "spacy.util.fix_random_seed(1)\n",
        "optimizer = nlp.begin_training()\n",
        "\n",
        "losses = {}\n",
        "for epoch in range(10):\n",
        "    random.shuffle(train_data)\n",
        "    # Create the batch generator with batch size = 8\n",
        "    batches = minibatch(train_data, size=8)\n",
        "    # Iterate through minibatches\n",
        "    for batch in batches:\n",
        "        # Each batch is a list of (text, label) but we need to\n",
        "        # send separate lists for texts and labels to update().\n",
        "        # This is a quick way to split a list of tuples into lists\n",
        "        texts, labels = zip(*batch)\n",
        "        nlp.update(texts, labels, sgd=optimizer, losses=losses)\n",
        "    print(losses)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'textcat': 0.4318974639753037}\n",
            "{'textcat': 0.6474976848384131}\n",
            "{'textcat': 0.7842155152014469}\n",
            "{'textcat': 0.8716684448577046}\n",
            "{'textcat': 0.9280940141270146}\n",
            "{'textcat': 0.9655780721800677}\n",
            "{'textcat': 0.9939652629180886}\n",
            "{'textcat': 1.0127977390059284}\n",
            "{'textcat': 1.0275638534046354}\n",
            "{'textcat': 1.0378532154302862}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BBbBY0bfrcmv",
        "colab_type": "code",
        "outputId": "9613926f-d1ce-4c41-fee1-eab45e516df1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "texts = [\"Are you ready for the tea party????? It's gonna be wild\",\n",
        "         \"URGENT Reply to this message for GUARANTEED FREE TEA\" ]\n",
        "docs = [nlp.tokenizer(text) for text in texts]\n",
        "    \n",
        "# Use textcat to get the scores for each doc\n",
        "textcat = nlp.get_pipe('textcat')\n",
        "scores, _ = textcat.predict(docs)\n",
        "\n",
        "print(scores)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[9.9994397e-01 5.6023709e-05]\n",
            " [1.1491287e-02 9.8850876e-01]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O_ZAKe16spMy",
        "colab_type": "code",
        "outputId": "7916b3f5-b9b5-4493-f05d-6fbb7f657683",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "# From the scores, find the label with the highest score/probability\n",
        "predicted_labels = scores.argmax(axis=1)\n",
        "print([textcat.labels[label] for label in predicted_labels])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['ham', 'spam']\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}